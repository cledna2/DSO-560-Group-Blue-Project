{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import difflib\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import logging\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 246</th>\n",
       "      <th>Unnamed: 247</th>\n",
       "      <th>Unnamed: 248</th>\n",
       "      <th>Unnamed: 249</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "      <th>Unnamed: 255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSRPSZTDW2PGK1YWYXJGKZZ0</td>\n",
       "      <td>FILA</td>\n",
       "      <td>400010319073</td>\n",
       "      <td>Original Fitness Sneakers</td>\n",
       "      <td>Vintage Fitness leather sneakers with logo pri...</td>\n",
       "      <td>TheMensStore/Shoes/Sneakers/LowTop</td>\n",
       "      <td>2019-11-15 23:36:38.98161+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/fila-original-...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id brand           mpn                       name  \\\n",
       "0  01DSRPSZTDW2PGK1YWYXJGKZZ0  FILA  400010319073  Original Fitness Sneakers   \n",
       "\n",
       "                                         description  \\\n",
       "0  Vintage Fitness leather sneakers with logo pri...   \n",
       "\n",
       "                       brand_category                    created_at  \\\n",
       "0  TheMensStore/Shoes/Sneakers/LowTop  2019-11-15 23:36:38.98161+00   \n",
       "\n",
       "                      updated_at  deleted_at  \\\n",
       "0  2019-12-19 20:40:30.786144+00         NaN   \n",
       "\n",
       "                                 brand_canonical_url  ... Unnamed: 246  \\\n",
       "0  https://www.saksfifthavenue.com/fila-original-...  ...          NaN   \n",
       "\n",
       "  Unnamed: 247 Unnamed: 248  Unnamed: 249  Unnamed: 250  Unnamed: 251  \\\n",
       "0          NaN          NaN           NaN           NaN           NaN   \n",
       "\n",
       "   Unnamed: 252  Unnamed: 253  Unnamed: 254  Unnamed: 255  \n",
       "0           NaN           NaN           NaN           NaN  \n",
       "\n",
       "[1 rows x 256 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Full+data.csv')\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42373, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce to non nan columns\n",
    "cols = data.columns[:14]\n",
    "data = data.loc[:,cols]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>mpn</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>saleable</th>\n",
       "      <th>details</th>\n",
       "      <th>created_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>notes</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>5529544</td>\n",
       "      <td>A.L.C.</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Lennox High Waist Cotton &amp; Linen Pants</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>5021</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>True to size. High rise.\\n31\" inseam; 14\" leg ...</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High-rise trousers tailored from a cool Italia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id      mpn   brand brand_category  \\\n",
       "0  01E5ZXP5H0BTEZT9QD2HRZJ47A  5529544  A.L.C.        Unknown   \n",
       "\n",
       "                                     name labels  \\\n",
       "0  Lennox High Waist Cotton & Linen Pants     []   \n",
       "\n",
       "                         updated_at  bc_product_id  \\\n",
       "0  2020-04-17 15:44:57.785000+00:00           5021   \n",
       "\n",
       "                           saleable  \\\n",
       "0  2020-04-17 15:44:57.785000+00:00   \n",
       "\n",
       "                                             details  \\\n",
       "0  True to size. High rise.\\n31\" inseam; 14\" leg ...   \n",
       "\n",
       "                         created_at  \\\n",
       "0  2020-04-15 21:59:56.695000+00:00   \n",
       "\n",
       "                                 brand_canonical_url notes  \\\n",
       "0  https://shop.nordstrom.com/s/a-l-c-lennox-high...   NaN   \n",
       "\n",
       "                                         description  \n",
       "0  High-rise trousers tailored from a cool Italia...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import extra data\n",
    "extra_data = pd.read_csv('extra_data.csv')\n",
    "extra_data.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to use from extra_data\n",
    "cols = ['product_id', 'brand', 'name', 'description', 'brand_category','details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data = extra_data.loc[:,cols]\n",
    "data = data.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate data and extra data\n",
    "full_data = pd.concat([data,extra_data])\n",
    "len(full_data) == len(data) + len(extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.fillna('UNKNOWNTOKEN',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will join brand and brand_category together to brand_info for use in predictions\n",
    "\n",
    "#full_data['brand_info'] = full_data['brand']+full_data['brand_category']+ \" \" +full_data['brand_canonical_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id        0\n",
       "brand             0\n",
       "name              0\n",
       "description       0\n",
       "brand_category    0\n",
       "details           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_style_all = pd.read_csv('color.csv',index_col = 0)\n",
    "data_color = pd.merge(full_data,tags_style_all,on='product_id', how = 'inner')\n",
    "#data_label.to_csv('data_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39956, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_color.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "stop = set(STOPWORDS)\n",
    "def remove_stopwords(data_col):\n",
    "    new_list = []\n",
    "    a = data_col\n",
    "    for i in range(0,len(a)):\n",
    "        words = word_tokenize(a[i])\n",
    "        res_words = []\n",
    "        for word in words:\n",
    "            if word not in stop:\n",
    "                res_words.append(word)\n",
    "            sentence = \" \".join(res_words)\n",
    "        new_list.append(sentence)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from each of the 4 columns\n",
    "data_color['description'] = remove_stopwords(data_color['description'])\n",
    "data_color['details'] = remove_stopwords(data_color['details'])\n",
    "data_color['name'] = remove_stopwords(data_color['name'])\n",
    "data_color['brand'] = remove_stopwords(data_color['brand'])\n",
    "data_color['brand_category'] = remove_stopwords(data_color['brand_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do regex cleaning\n",
    "def reg_clean(data,col):\n",
    "    new_list = []\n",
    "    for i in range(0,len(data)):\n",
    "        #special characters \n",
    "        a = re.sub(r'[^ a-zA-Z0-9]',' ',data.loc[i,col])\n",
    "        #new lines\n",
    "        a = re.sub(r'\\n',' ', a)\n",
    "        #remove multiple spaces by a single space\n",
    "        a = re.sub(r'\\s+',' ',a)\n",
    "        #timestamp\n",
    "        a = re.sub(r'\\b[0-9]{1,}am|[0-9]{1,}pm|[0-9]{4,}|[0-9]ish|1st|2nd|3rd|[0-9]{1,2}th|31st|[0-9]{1,}min(?:utes)?s?|[0-9]{1,}h(?:ou)?rs?|[0-9]{3,}\\b','timestamp',a)\n",
    "        a = re.sub(r'\\b[0-9]{1,}timestamp\\b','timestamp',a)\n",
    "        #any numbers as digit\n",
    "        a = re.sub(r'\\b\\d+\\b','digit',a)\n",
    "        #number followed by a variable\n",
    "        a = re.sub(r'\\b\\d{1,}[a-z]{0,}[0-9]{0,}','varchar',a)\n",
    "        #html codes\n",
    "        a = re.sub(r'<.+?>','html',a)\n",
    "        a = re.sub(r'https|www|com','html',a)\n",
    "        # additional stopwords\n",
    "        a = re.sub(r'\\ba\\b', '', a, flags = re.IGNORECASE)\n",
    "        a = re.sub(r'\\bthis|the\\b', '',a, flags = re.IGNORECASE)\n",
    "        new_list.append(a)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform regex cleaning on each column\n",
    "data_color['description'] = reg_clean(data_color,'description')\n",
    "data_color['details'] = reg_clean(data_color,'details')\n",
    "data_color['brand'] = reg_clean(data_color,'brand')\n",
    "data_color['name'] = reg_clean(data_color, 'name')\n",
    "data_color['brand_category'] = reg_clean(data_color,'brand_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to lemmatize columns\n",
    "def lemmatize_sentence(data_col):\n",
    "    new_list = []\n",
    "    a = data_col \n",
    "    for i in range(0,len(a)):\n",
    "        words = word_tokenize(a[i])\n",
    "        res_words = []\n",
    "        for word in words:\n",
    "            res_words.append(lemmatizer.lemmatize(word).strip(string.punctuation))\n",
    "        sentence = \" \".join(res_words)\n",
    "        new_list.append(sentence)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize each column\n",
    "data_color['description'] = lemmatize_sentence(data_color['description'])\n",
    "data_color['details'] = lemmatize_sentence(data_color['details'])\n",
    "data_color['brand'] = lemmatize_sentence(data_color['brand'])\n",
    "data_color['brand_category'] = lemmatize_sentence(data_color['brand_category'])\n",
    "data_color['name'] = lemmatize_sentence(data_color['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to start collocation\n",
    "stopwords_coll = set(stopwords.words('english') + [\".\",'.', \",\",\":\", \"''\", \"'s\", \"'\", \"``\", \"(\", \")\", \"-\",\"timestamp\",\"varchar\",\"html\",\"digit\"])\n",
    "filter_stops = lambda w: len(w) < 3 or w in stopwords_coll\n",
    "def collocation_list(data_col):\n",
    "    new_list = []\n",
    "    for i in range(0,len(data_col)):\n",
    "        words = word_tokenize(data_col[i])\n",
    "        res_words = []\n",
    "        for word in words:\n",
    "            if word not in stopwords_coll:\n",
    "                res_words.append(word)\n",
    "        new_list.append(res_words)\n",
    "    return(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['brand', 'brand_category', 'description', 'name','details']\n",
    "n_list = []\n",
    "for col in cols:\n",
    "    n_list.append(collocation_list(full_data[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find that dry clean, machine wash, 'fits true to size', 'made in italy' \n",
    "# should be collated together\n",
    "\n",
    "col_list = [['Dry', 'clean'], ['Machine', 'wash'], ['true', 'size'],['fit', 'true_size'], ['Fits', 'true_size'],  \n",
    "            ['Made', 'Italy']]\n",
    "data_col = data_color['details']\n",
    "new_list = []\n",
    "clean_list = ['Dry','wash','Italy', 'size']\n",
    "for i in range(0,len(data_col)):\n",
    "    words = word_tokenize(data_col[i])\n",
    "    len_words = len(words)-1\n",
    "    for i in range(0,len_words):\n",
    "        bi_word = []\n",
    "        j = i+1\n",
    "        bi_word.append(words[i])\n",
    "        bi_word.append(words[j])\n",
    "        if(bi_word in col_list):\n",
    "            sentence = \"_\".join(bi_word)\n",
    "            words[i] = sentence\n",
    "    for word in words:\n",
    "        if word in clean_list:\n",
    "            words.remove(word)\n",
    "    res_word = []\n",
    "    for word in words:\n",
    "        res_word.append(word)\n",
    "    sentence = \" \".join(res_word)\n",
    "    new_list.append(sentence)\n",
    "data_color['details'] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find that wide leg, ankle boot, high waist, high rise \n",
    "# should be collated together\n",
    "\n",
    "col_list = [['wide','leg'], ['ankle', 'boot'], ['High', 'Waist'], ['Wide', 'Leg'], ['High', 'Rise'], \n",
    "            ['straight', 'leg'], ['shoulder', 'bag']]\n",
    "data_col = data_color['name']\n",
    "new_list = []\n",
    "clean_list = ['leg', 'boot', 'Waist', 'Leg', 'Rise','bag']\n",
    "for i in range(0,len(data_col)):\n",
    "    words = word_tokenize(data_col[i])\n",
    "    len_words = len(words)-1\n",
    "    for i in range(0,len_words):\n",
    "        bi_word = []\n",
    "        j = i+1\n",
    "        bi_word.append(words[i])\n",
    "        bi_word.append(words[j])\n",
    "        if(bi_word in col_list):\n",
    "            sentence = \"_\".join(bi_word)\n",
    "            words[i] = sentence\n",
    "    for word in words:\n",
    "        if word in clean_list:\n",
    "            words.remove(word)\n",
    "    res_word = []\n",
    "    for word in words:\n",
    "        res_word.append(word)\n",
    "    sentence = \" \".join(res_word)\n",
    "    new_list.append(sentence)\n",
    "data_color['name'] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [['Dry','clean'], ['Machine', 'wash'], ['Made', 'Italy'], ['wide', 'leg'], ['best', 'selling'], \n",
    "            ['high', 'waisted'], ['pencil', 'skirt'], ['High', 'Rise'], ['high','rise'], ['Hand','wash']]\n",
    "data_col = data_color['description']\n",
    "new_list = []\n",
    "clean_list = ['clean', 'wash', 'Italy', 'leg', 'selling','waisted', 'skirt','Rise', 'rise']\n",
    "for i in range(0,len(data_col)):\n",
    "    words = word_tokenize(data_col[i])\n",
    "    len_words = len(words)-1\n",
    "    for i in range(0,len_words):\n",
    "        bi_word = []\n",
    "        j = i+1\n",
    "        bi_word.append(words[i])\n",
    "        bi_word.append(words[j])\n",
    "        if(bi_word in col_list):\n",
    "            sentence = \"_\".join(bi_word)\n",
    "            words[i] = sentence\n",
    "    for word in words:\n",
    "        if word in clean_list:\n",
    "            words.remove(word)\n",
    "    res_word = []\n",
    "    for word in words:\n",
    "        res_word.append(word)\n",
    "    sentence = \" \".join(res_word)\n",
    "    new_list.append(sentence)\n",
    "data_color['description'] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find that  should be collocated together\n",
    "\n",
    "col_list = [['New', 'York'], ['Jimmy','Choo'], ['Banana','Republic'], ['Victoria','Beckham']]\n",
    "data_col = data_color['brand']\n",
    "new_list = []\n",
    "clean_list = ['York', 'Choo','Republic', 'Beckham']\n",
    "for i in range(0,len(data_col)):\n",
    "    words = word_tokenize(data_col[i])\n",
    "    len_words = len(words)-1\n",
    "    for i in range(0,len_words):\n",
    "        bi_word = []\n",
    "        j = i+1\n",
    "        bi_word.append(words[i])\n",
    "        bi_word.append(words[j])\n",
    "        if(bi_word in col_list):\n",
    "            sentence = \"_\".join(bi_word)\n",
    "            words[i] = sentence\n",
    "    for word in words:\n",
    "        if word in clean_list:\n",
    "            words.remove(word)\n",
    "    res_word = []\n",
    "    for word in words:\n",
    "        res_word.append(word)\n",
    "    sentence = \" \".join(res_word)\n",
    "    new_list.append(sentence)\n",
    "data_color['brand'] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [['Mid', 'Heel'], ['Shoulder', 'Bags']]\n",
    "data_col = data_color['brand_category']\n",
    "new_list = []\n",
    "clean_list = ['Heel', 'Bags']\n",
    "for i in range(0,len(data_col)):\n",
    "    words = word_tokenize(data_col[i])\n",
    "    len_words = len(words)-1\n",
    "    for i in range(0,len_words):\n",
    "        bi_word = []\n",
    "        j = i+1\n",
    "        bi_word.append(words[i])\n",
    "        bi_word.append(words[j])\n",
    "        if(bi_word in col_list):\n",
    "            sentence = \"_\".join(bi_word)\n",
    "            words[i] = sentence\n",
    "    for word in words:\n",
    "        if word in clean_list:\n",
    "            words.remove(word)\n",
    "    res_word = []\n",
    "    for word in words:\n",
    "        res_word.append(word)\n",
    "    sentence = \" \".join(res_word)\n",
    "    new_list.append(sentence)\n",
    "data_color['brand_category'] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id           0\n",
       "brand                0\n",
       "name                 0\n",
       "description          0\n",
       "brand_category       0\n",
       "details              0\n",
       "product_color_id     0\n",
       "attribute_name       0\n",
       "attribute_value      0\n",
       "is_black            14\n",
       "is_beige            14\n",
       "is_burgundy         14\n",
       "is_white            14\n",
       "is_gray             14\n",
       "is_gold             14\n",
       "is_blue             14\n",
       "is_neutral          14\n",
       "is_pink             14\n",
       "is_orange           14\n",
       "is_navy             14\n",
       "is_brown            14\n",
       "is_red              14\n",
       "is_yellow           14\n",
       "is_multi            14\n",
       "is_green            14\n",
       "is_silver           14\n",
       "is_teal             14\n",
       "is_purple           14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_color.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_color.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id          0\n",
       "brand               0\n",
       "name                0\n",
       "description         0\n",
       "brand_category      0\n",
       "details             0\n",
       "product_color_id    0\n",
       "attribute_name      0\n",
       "attribute_value     0\n",
       "is_black            0\n",
       "is_beige            0\n",
       "is_burgundy         0\n",
       "is_white            0\n",
       "is_gray             0\n",
       "is_gold             0\n",
       "is_blue             0\n",
       "is_neutral          0\n",
       "is_pink             0\n",
       "is_orange           0\n",
       "is_navy             0\n",
       "is_brown            0\n",
       "is_red              0\n",
       "is_yellow           0\n",
       "is_multi            0\n",
       "is_green            0\n",
       "is_silver           0\n",
       "is_teal             0\n",
       "is_purple           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_color.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute 0's to na's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the tf-idf vectorizer\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b[a-zA-Z]{3,}\\b',stop_words=\"english\",binary = True,min_df = 0.005,max_df = 0.7,max_features =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing our test/full data\n",
    "columns = ['description','details','brand', 'brand_category', 'name']\n",
    "model_data=pd.DataFrame()\n",
    "for j in columns:\n",
    "    corpus = []\n",
    "    for i in range(0,len(data_color)):\n",
    "        corpus.append(data_color.loc[i,j])\n",
    "    vect = vectorizer.fit_transform(corpus)\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    c=pd.DataFrame(vect.toarray().transpose(), index=terms)\n",
    "    model_data=pd.concat([model_data,c.T],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39956, 890)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39956, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_color.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_black', 'is_beige', 'is_burgundy', 'is_white', 'is_gray', 'is_gold',\n",
       "       'is_blue', 'is_neutral', 'is_pink', 'is_orange', 'is_navy', 'is_brown',\n",
       "       'is_red', 'is_yellow', 'is_multi', 'is_green', 'is_silver', 'is_teal',\n",
       "       'is_purple'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_color.columns[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(n_jobs=1, C=1e5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data_color.columns[9:]\n",
    "for col in cols:\n",
    "    x=model_data\n",
    "    y=data_color[col].values\n",
    "    logreg.fit(x,y)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_log = logreg.predict(x)\n",
    "    data_color[col+'_predicted'] = predictions_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39956, 47)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_color.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_color.to_csv('data_color_predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data = pd.read_csv('subset_color.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
