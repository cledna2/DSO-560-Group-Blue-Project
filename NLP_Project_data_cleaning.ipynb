{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import difflib\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data file for product_information\n",
    "data = pd.read_csv('Full+data.csv')\n",
    "#data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 246</th>\n",
       "      <th>Unnamed: 247</th>\n",
       "      <th>Unnamed: 248</th>\n",
       "      <th>Unnamed: 249</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "      <th>Unnamed: 255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSRPSZTDW2PGK1YWYXJGKZZ0</td>\n",
       "      <td>FILA</td>\n",
       "      <td>400010319073</td>\n",
       "      <td>Original Fitness Sneakers</td>\n",
       "      <td>Vintage Fitness leather sneakers with logo pri...</td>\n",
       "      <td>TheMensStore/Shoes/Sneakers/LowTop</td>\n",
       "      <td>2019-11-15 23:36:38.98161+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/fila-original-...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DSQXJBX0R7DCW7KTAC1SW547</td>\n",
       "      <td>CHANEL</td>\n",
       "      <td>400011497371</td>\n",
       "      <td>HAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-15 16:15:34.809725+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/chanel-hat/pro...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id   brand           mpn  \\\n",
       "0  01DSRPSZTDW2PGK1YWYXJGKZZ0    FILA  400010319073   \n",
       "1  01DSQXJBX0R7DCW7KTAC1SW547  CHANEL  400011497371   \n",
       "\n",
       "                        name  \\\n",
       "0  Original Fitness Sneakers   \n",
       "1                        HAT   \n",
       "\n",
       "                                         description  \\\n",
       "0  Vintage Fitness leather sneakers with logo pri...   \n",
       "1                                                NaN   \n",
       "\n",
       "                       brand_category                     created_at  \\\n",
       "0  TheMensStore/Shoes/Sneakers/LowTop   2019-11-15 23:36:38.98161+00   \n",
       "1                             Unknown  2019-11-15 16:15:34.809725+00   \n",
       "\n",
       "                      updated_at  deleted_at  \\\n",
       "0  2019-12-19 20:40:30.786144+00         NaN   \n",
       "1  2019-12-19 20:40:30.786144+00         NaN   \n",
       "\n",
       "                                 brand_canonical_url  ... Unnamed: 246  \\\n",
       "0  https://www.saksfifthavenue.com/fila-original-...  ...          NaN   \n",
       "1  https://www.saksfifthavenue.com/chanel-hat/pro...  ...          NaN   \n",
       "\n",
       "  Unnamed: 247 Unnamed: 248  Unnamed: 249  Unnamed: 250  Unnamed: 251  \\\n",
       "0          NaN          NaN           NaN           NaN           NaN   \n",
       "1          NaN          NaN           NaN           NaN           NaN   \n",
       "\n",
       "   Unnamed: 252  Unnamed: 253  Unnamed: 254  Unnamed: 255  \n",
       "0           NaN           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN           NaN  \n",
       "\n",
       "[2 rows x 256 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with all na's \n",
    "data = data.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6621, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extra_information data\n",
    "extra_data = pd.read_csv('extra_data.csv')\n",
    "extra_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra_data and Full_data do not have the same columns. So, we subset the data for only important columns and the join the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are interested in these columns as they have the maximum information\n",
    "cols = ['product_id', 'brand','description', 'brand_category', 'name','details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6621, 6)\n",
      "(42373, 6)\n"
     ]
    }
   ],
   "source": [
    "extra_data = extra_data.loc[:,cols]\n",
    "data = data.loc[:,cols]\n",
    "print(extra_data.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.concat([data,extra_data])\n",
    "len(full_data) == len(data) + len(extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48994"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicate product names\n",
    "full_data.drop_duplicates(subset=['product_id'], keep=\"first\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id        0\n",
       "brand             0\n",
       "description       0\n",
       "brand_category    0\n",
       "name              0\n",
       "details           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#treating for na variables\n",
    "full_data.fillna('UNKNOWNTOKEN',inplace=True)\n",
    "full_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>name</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSRPSZTDW2PGK1YWYXJGKZZ0</td>\n",
       "      <td>fila</td>\n",
       "      <td>vintage fitness leather sneakers with logo pri...</td>\n",
       "      <td>themensstore/shoes/sneakers/lowtop</td>\n",
       "      <td>original fitness sneakers</td>\n",
       "      <td>leather/synthetic upper\\nlace-up closure\\ntext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DSQXJBX0R7DCW7KTAC1SW547</td>\n",
       "      <td>chanel</td>\n",
       "      <td>unknowntoken</td>\n",
       "      <td>unknown</td>\n",
       "      <td>hat</td>\n",
       "      <td>wool tweed &amp; felt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id   brand  \\\n",
       "0  01DSRPSZTDW2PGK1YWYXJGKZZ0    fila   \n",
       "1  01DSQXJBX0R7DCW7KTAC1SW547  chanel   \n",
       "\n",
       "                                         description  \\\n",
       "0  vintage fitness leather sneakers with logo pri...   \n",
       "1                                       unknowntoken   \n",
       "\n",
       "                       brand_category                       name  \\\n",
       "0  themensstore/shoes/sneakers/lowtop  original fitness sneakers   \n",
       "1                             unknown                        hat   \n",
       "\n",
       "                                             details  \n",
       "0  leather/synthetic upper\\nlace-up closure\\ntext...  \n",
       "1                                  wool tweed & felt  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean the data for upper case\n",
    "cols = full_data.columns[1:]\n",
    "for col in cols:\n",
    "    full_data[col] = full_data[col].str.lower()\n",
    "full_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we merge the all tags provided to us and join it with the product information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21925, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the tags\n",
    "tags = pd.read_excel('USC+Product+Attribute+Data+03302020.xlsx')\n",
    "tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97420, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read additional tags\n",
    "add_tags = pd.read_csv('usc_additional_tags.csv')\n",
    "add_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join them together\n",
    "all_tags = pd.concat([tags,add_tags])\n",
    "len(all_tags) == len(tags) + len(add_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119345, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#treat the tags for name = \"Style\"\n",
    "all_tags = all_tags.loc[:,['product_id','attribute_name','attribute_value']]\n",
    "all_tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subsetting the tags just for attribute_name = style. So, that when we merge back there is no multiple records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All :(18335, 3)\n",
      "Clean:(13357, 3)\n"
     ]
    }
   ],
   "source": [
    "tags_style = all_tags[all_tags['attribute_name']=='style']\n",
    "print(f'All :{tags_style.shape}')\n",
    "tags_style = tags_style.drop_duplicates()\n",
    "print(f'Clean:{tags_style.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Casual', 'Modern', 'Androgynous', 'Romantic', 'Boho',\n",
       "       'Business Casual', 'Edgy', 'Glam', 'Classic', 'Athleisure',\n",
       "       'Retro', 'modern', 'businesscasual', 'classic', 'glam', 'edgy',\n",
       "       'casual', 'retro', 'boho', 'androgynous', 'romantic', 'athleisure'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking unique values. They should be 11\n",
    "tags_style['attribute_value'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that naming is not consistent. So, we clean the data to make it same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean:(10868, 3)\n"
     ]
    }
   ],
   "source": [
    "tags_style['attribute_value'] = tags_style['attribute_value'].str.lower()\n",
    "tags_style = tags_style.drop_duplicates()\n",
    "print(f'Clean:{tags_style.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['casual', 'modern', 'androgynous', 'romantic', 'boho',\n",
       "       'business casual', 'edgy', 'glam', 'classic', 'athleisure',\n",
       "       'retro', 'businesscasual'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_style['attribute_value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see that business casual and business casual are messed up. So, we clean this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_style = tags_style.reset_index(drop = True)\n",
    "for i in range(0,len(tags_style)):\n",
    "    if(tags_style.loc[i,'attribute_value']=='businesscasual'):\n",
    "        tags_style.loc[i,'attribute_value'] = 'business casual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique product id tags for style are : 3916\n"
     ]
    }
   ],
   "source": [
    "a = len(tags_style['product_id'].unique())\n",
    "print(f'Total Unique product id tags for style are : {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tag_count = tags_style['product_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product count with only one unique tag are :233\n"
     ]
    }
   ],
   "source": [
    "#printing number of products with just 1 tag\n",
    "product_list = []\n",
    "for i in product_tag_count.index:\n",
    "    if(product_tag_count[i]==1):\n",
    "        product_list.append(i)\n",
    "print(f'product count with only one unique tag are :{len(product_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product count with multiple unique tag are :3683\n"
     ]
    }
   ],
   "source": [
    "#printing number of products with more than 1 tag\n",
    "product_list = []\n",
    "for i in product_tag_count.index:\n",
    "    if(product_tag_count[i]>1):\n",
    "        product_list.append(i)\n",
    "print(f'product count with multiple unique tag are :{len(product_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we can see there can be multiple value so we create flag for each type of product_tag\n",
    "\n",
    "list_of_style = tags_style['attribute_value'].unique()\n",
    "\n",
    "for j in list_of_style:\n",
    "    for i in range(0,len(tags_style)):\n",
    "        if(tags_style.loc[i,'attribute_value'] == j):\n",
    "            tags_style.loc[i,'is_'+j] = 1\n",
    "        else:\n",
    "            tags_style.loc[i,'is_'+j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>is_casual</th>\n",
       "      <th>is_modern</th>\n",
       "      <th>is_androgynous</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_boho</th>\n",
       "      <th>is_business casual</th>\n",
       "      <th>is_edgy</th>\n",
       "      <th>is_glam</th>\n",
       "      <th>is_classic</th>\n",
       "      <th>is_athleisure</th>\n",
       "      <th>is_retro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
       "      <td>style</td>\n",
       "      <td>casual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01E1JM43NQ3H17PB22EV3074NX</td>\n",
       "      <td>style</td>\n",
       "      <td>modern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DT0DJ6GQNF86VZ1EAP047SVC</td>\n",
       "      <td>style</td>\n",
       "      <td>modern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DPH1DEN9G2WM7WAMJMD0A9W4</td>\n",
       "      <td>style</td>\n",
       "      <td>casual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DS3SKHPXXH6AN4362MZYYQAT</td>\n",
       "      <td>style</td>\n",
       "      <td>androgynous</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id attribute_name attribute_value  is_casual  \\\n",
       "0  01DPGV4YRP3Z8J85DASGZ1Y99W          style          casual        1.0   \n",
       "1  01E1JM43NQ3H17PB22EV3074NX          style          modern        0.0   \n",
       "2  01DT0DJ6GQNF86VZ1EAP047SVC          style          modern        0.0   \n",
       "3  01DPH1DEN9G2WM7WAMJMD0A9W4          style          casual        1.0   \n",
       "4  01DS3SKHPXXH6AN4362MZYYQAT          style     androgynous        0.0   \n",
       "\n",
       "   is_modern  is_androgynous  is_romantic  is_boho  is_business casual  \\\n",
       "0        0.0             0.0          0.0      0.0                 0.0   \n",
       "1        1.0             0.0          0.0      0.0                 0.0   \n",
       "2        1.0             0.0          0.0      0.0                 0.0   \n",
       "3        0.0             0.0          0.0      0.0                 0.0   \n",
       "4        0.0             1.0          0.0      0.0                 0.0   \n",
       "\n",
       "   is_edgy  is_glam  is_classic  is_athleisure  is_retro  \n",
       "0      0.0      0.0         0.0            0.0       0.0  \n",
       "1      0.0      0.0         0.0            0.0       0.0  \n",
       "2      0.0      0.0         0.0            0.0       0.0  \n",
       "3      0.0      0.0         0.0            0.0       0.0  \n",
       "4      0.0      0.0         0.0            0.0       0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_style.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we create 11 different tag df with respective style and remove duplicates\n",
    "#casual\n",
    "casual = tags_style[['product_id','is_casual']]\n",
    "tags_casual = casual.groupby(['product_id'])['is_casual'].max().reset_index()\n",
    "#modern\n",
    "modern = tags_style[['product_id','is_modern']]\n",
    "tags_modern = modern.groupby(['product_id'])['is_modern'].max().reset_index()\n",
    "#androgynous\n",
    "androgynous = tags_style[['product_id','is_androgynous']]\n",
    "tags_androgynous = androgynous.groupby(['product_id'])['is_androgynous'].max().reset_index()\n",
    "#romantic\n",
    "romantic = tags_style[['product_id','is_romantic']]\n",
    "tags_romantic = romantic.groupby(['product_id'])['is_romantic'].max().reset_index()\n",
    "#boho\n",
    "boho = tags_style[['product_id','is_boho']]\n",
    "tags_boho = boho.groupby(['product_id'])['is_boho'].max().reset_index()\n",
    "#business casual\n",
    "business_casual = tags_style[['product_id','is_business casual']]\n",
    "tags_business_casual = business_casual.groupby(['product_id'])['is_business casual'].max().reset_index()\n",
    "#edgy\n",
    "edgy = tags_style[['product_id','is_edgy']]\n",
    "tags_edgy = edgy.groupby(['product_id'])['is_edgy'].max().reset_index()\n",
    "#glam\n",
    "glam = tags_style[['product_id','is_glam']]\n",
    "tags_glam = glam.groupby(['product_id'])['is_glam'].max().reset_index()\n",
    "#classic\n",
    "classic = tags_style[['product_id','is_classic']]\n",
    "tags_classic = classic.groupby(['product_id'])['is_classic'].max().reset_index()\n",
    "#athleisure\n",
    "athleisure = tags_style[['product_id','is_athleisure']]\n",
    "tags_athleisure = athleisure.groupby(['product_id'])['is_athleisure'].max().reset_index()\n",
    "#retro\n",
    "retro = tags_style[['product_id','is_retro']]\n",
    "tags_retro = retro.groupby(['product_id'])['is_retro'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now, we need to add different tags one final tag df\n",
    "df_list = [tags_modern,tags_androgynous,tags_romantic,tags_boho,tags_business_casual,tags_edgy,tags_glam,tags_classic,tags_athleisure,tags_retro]\n",
    "for df_ in df_list:\n",
    "    tags_casual = pd.merge(tags_casual, df_, on='product_id', how='left')\n",
    "tags_style_all = tags_casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags_style_all.to_csv('style.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3916"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags_style_all['product_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we go back to cleaning our actual data. Let's merge tags_style_all and all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = pd.merge(full_data,tags_style_all,on='product_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's remove the basic stop words from the dataset\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "stop = set(STOPWORDS)\n",
    "def remove_stopwords(data_col):\n",
    "    new_list = []\n",
    "    a = data_col\n",
    "    for i in range(0,len(a)):\n",
    "        words = word_tokenize(a[i])\n",
    "        res_words = []\n",
    "        for word in words:\n",
    "            if word not in stop:\n",
    "                res_words.append(word)\n",
    "            sentence = \" \".join(res_words)\n",
    "        new_list.append(sentence)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>name</th>\n",
       "      <th>details</th>\n",
       "      <th>is_casual</th>\n",
       "      <th>is_modern</th>\n",
       "      <th>is_androgynous</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_boho</th>\n",
       "      <th>is_business casual</th>\n",
       "      <th>is_edgy</th>\n",
       "      <th>is_glam</th>\n",
       "      <th>is_classic</th>\n",
       "      <th>is_athleisure</th>\n",
       "      <th>is_retro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DTJCERF6F4NRZ2WSJFFA1EYS</td>\n",
       "      <td>theory</td>\n",
       "      <td>beige stretch-silk slips 93 % silk , 7 % spand...</td>\n",
       "      <td>clothing / tops / tanks camis</td>\n",
       "      <td>teah stretch-silk camisole</td>\n",
       "      <td>fits true size , normal size cut slightly loos...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DVPBJ6464YKYGVAE0A1HMKGN</td>\n",
       "      <td>alexander wang</td>\n",
       "      <td>black velvet concealed hook zip fastening 65 %...</td>\n",
       "      <td>clothing / dresses / mini</td>\n",
       "      <td>layered velvet mini dress</td>\n",
       "      <td>fits true size , normal size designed fitted b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id           brand  \\\n",
       "0  01DTJCERF6F4NRZ2WSJFFA1EYS          theory   \n",
       "1  01DVPBJ6464YKYGVAE0A1HMKGN  alexander wang   \n",
       "\n",
       "                                         description  \\\n",
       "0  beige stretch-silk slips 93 % silk , 7 % spand...   \n",
       "1  black velvet concealed hook zip fastening 65 %...   \n",
       "\n",
       "                  brand_category                        name  \\\n",
       "0  clothing / tops / tanks camis  teah stretch-silk camisole   \n",
       "1      clothing / dresses / mini   layered velvet mini dress   \n",
       "\n",
       "                                             details  is_casual  is_modern  \\\n",
       "0  fits true size , normal size cut slightly loos...        1.0        1.0   \n",
       "1  fits true size , normal size designed fitted b...        0.0        1.0   \n",
       "\n",
       "   is_androgynous  is_romantic  is_boho  is_business casual  is_edgy  is_glam  \\\n",
       "0             0.0          1.0      0.0                 1.0      0.0      1.0   \n",
       "1             0.0          0.0      0.0                 0.0      0.0      1.0   \n",
       "\n",
       "   is_classic  is_athleisure  is_retro  \n",
       "0         1.0            0.0       0.0  \n",
       "1         1.0            0.0       0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean the data for stopwords for every columns\n",
    "cols = ['brand','description', 'brand_category', 'name','details']\n",
    "for col in cols:\n",
    "    data_label[col] = remove_stopwords(data_label[col])\n",
    "data_label.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's clean description based on some rules\n",
    "#clean the data using regex\n",
    "def reg_clean(data,col):\n",
    "    new_list = []\n",
    "    for i in range(0,len(data)):\n",
    "        #special characters \n",
    "        a = re.sub(r'[^ a-zA-Z0-9]','',data.loc[i,col])\n",
    "        #remove multiple spaces by a single space\n",
    "        a = re.sub(r'\\s+',' ',a)\n",
    "        #timestamp\n",
    "        a = re.sub(r'\\b[0-9]{1,}am|[0-9]{1,}pm|[0-9]{4,}|[0-9]ish|1st|2nd|3rd|[0-9]{1,2}th|31st|[0-9]{1,}min(?:utes)?s?|[0-9]{1,}h(?:ou)?rs?|[0-9]{3,}\\b','timestamp',a)\n",
    "        a = re.sub(r'\\b[0-9]{1,}timestamp\\b','timestamp',a)\n",
    "        #any numbers as digit\n",
    "        a = re.sub(r'\\b\\d{1,}\\b','digit',a)\n",
    "        #number followed by a variable\n",
    "        a = re.sub(r'\\b\\d{1,}[a-z]{0,}[0-9]{0,}','varchar',a)\n",
    "        #html codes\n",
    "        a = re.sub(r'<.+?>','html',a)\n",
    "        a = re.sub(r'https|www','html',a)\n",
    "        new_list.append(a)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>name</th>\n",
       "      <th>details</th>\n",
       "      <th>is_casual</th>\n",
       "      <th>is_modern</th>\n",
       "      <th>is_androgynous</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_boho</th>\n",
       "      <th>is_business casual</th>\n",
       "      <th>is_edgy</th>\n",
       "      <th>is_glam</th>\n",
       "      <th>is_classic</th>\n",
       "      <th>is_athleisure</th>\n",
       "      <th>is_retro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DTJCERF6F4NRZ2WSJFFA1EYS</td>\n",
       "      <td>theory</td>\n",
       "      <td>beige stretchsilk slips digit silk digit spand...</td>\n",
       "      <td>clothing tops tanks camis</td>\n",
       "      <td>teah stretchsilk camisole</td>\n",
       "      <td>fits true size normal size cut slightly loose ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DVPBJ6464YKYGVAE0A1HMKGN</td>\n",
       "      <td>alexander wang</td>\n",
       "      <td>black velvet concealed hook zip fastening digi...</td>\n",
       "      <td>clothing dresses mini</td>\n",
       "      <td>layered velvet mini dress</td>\n",
       "      <td>fits true size normal size designed fitted bus...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id           brand  \\\n",
       "0  01DTJCERF6F4NRZ2WSJFFA1EYS          theory   \n",
       "1  01DVPBJ6464YKYGVAE0A1HMKGN  alexander wang   \n",
       "\n",
       "                                         description  \\\n",
       "0  beige stretchsilk slips digit silk digit spand...   \n",
       "1  black velvet concealed hook zip fastening digi...   \n",
       "\n",
       "              brand_category                       name  \\\n",
       "0  clothing tops tanks camis  teah stretchsilk camisole   \n",
       "1      clothing dresses mini  layered velvet mini dress   \n",
       "\n",
       "                                             details  is_casual  is_modern  \\\n",
       "0  fits true size normal size cut slightly loose ...        1.0        1.0   \n",
       "1  fits true size normal size designed fitted bus...        0.0        1.0   \n",
       "\n",
       "   is_androgynous  is_romantic  is_boho  is_business casual  is_edgy  is_glam  \\\n",
       "0             0.0          1.0      0.0                 1.0      0.0      1.0   \n",
       "1             0.0          0.0      0.0                 0.0      0.0      1.0   \n",
       "\n",
       "   is_classic  is_athleisure  is_retro  \n",
       "0         1.0            0.0       0.0  \n",
       "1         1.0            0.0       0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean the data for regex for every column\n",
    "cols = ['brand','description', 'brand_category', 'name','details']\n",
    "for col in cols:\n",
    "    data_label[col] = reg_clean(data_label,col)\n",
    "data_label.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(map(lambda word: word.replace(\"\\n\", \"\"), open(\"20k.txt\").readlines()))\n",
    "words.add('unknowntoken')\n",
    "def spellcheck_document(text):\n",
    "    new_tokens = []\n",
    "    for token in word_tokenize(text):\n",
    "        matches = difflib.get_close_matches(token, words, n=1, cutoff=0.7)\n",
    "        if len(matches) == 0 or token.lower() in words:\n",
    "            new_tokens.append(token)\n",
    "        else:\n",
    "            new_tokens.append(matches[0])\n",
    "    return \" \".join(new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spellcheck is taking forever to run. Hence, commented this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell check the whole document apart from product_id we have added unknown_text as well so that it does not return unknown\n",
    "#cols = data_label.columns[1:4]\n",
    "#for col in cols:\n",
    "#    new_list = []\n",
    "#    for i in range(0,len(data_label)):\n",
    "#        new_list.append(spellcheck_document(data_label.loc[i,col]))\n",
    "#    data_label.col = new_list\n",
    "#    print(col)\n",
    "#data_label.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize\n",
    "def lemmatize_sentence(data_col):\n",
    "    new_list = []\n",
    "    a = data_col \n",
    "    for i in range(0,len(a)):\n",
    "        words = word_tokenize(a[i])\n",
    "        res_words = []\n",
    "        for word in words:\n",
    "            res_words.append(lemmatizer.lemmatize(word).strip(string.punctuation))\n",
    "        sentence = \" \".join(res_words)\n",
    "        new_list.append(sentence)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>name</th>\n",
       "      <th>details</th>\n",
       "      <th>is_casual</th>\n",
       "      <th>is_modern</th>\n",
       "      <th>is_androgynous</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_boho</th>\n",
       "      <th>is_business casual</th>\n",
       "      <th>is_edgy</th>\n",
       "      <th>is_glam</th>\n",
       "      <th>is_classic</th>\n",
       "      <th>is_athleisure</th>\n",
       "      <th>is_retro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DTJCERF6F4NRZ2WSJFFA1EYS</td>\n",
       "      <td>theory</td>\n",
       "      <td>beige stretchsilk slip digit silk digit spande...</td>\n",
       "      <td>clothing top tank camis</td>\n",
       "      <td>teah stretchsilk camisole</td>\n",
       "      <td>fit true size normal size cut slightly loose f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DVPBJ6464YKYGVAE0A1HMKGN</td>\n",
       "      <td>alexander wang</td>\n",
       "      <td>black velvet concealed hook zip fastening digi...</td>\n",
       "      <td>clothing dress mini</td>\n",
       "      <td>layered velvet mini dress</td>\n",
       "      <td>fit true size normal size designed fitted bust...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id           brand  \\\n",
       "0  01DTJCERF6F4NRZ2WSJFFA1EYS          theory   \n",
       "1  01DVPBJ6464YKYGVAE0A1HMKGN  alexander wang   \n",
       "\n",
       "                                         description           brand_category  \\\n",
       "0  beige stretchsilk slip digit silk digit spande...  clothing top tank camis   \n",
       "1  black velvet concealed hook zip fastening digi...      clothing dress mini   \n",
       "\n",
       "                        name  \\\n",
       "0  teah stretchsilk camisole   \n",
       "1  layered velvet mini dress   \n",
       "\n",
       "                                             details  is_casual  is_modern  \\\n",
       "0  fit true size normal size cut slightly loose f...        1.0        1.0   \n",
       "1  fit true size normal size designed fitted bust...        0.0        1.0   \n",
       "\n",
       "   is_androgynous  is_romantic  is_boho  is_business casual  is_edgy  is_glam  \\\n",
       "0             0.0          1.0      0.0                 1.0      0.0      1.0   \n",
       "1             0.0          0.0      0.0                 0.0      0.0      1.0   \n",
       "\n",
       "   is_classic  is_athleisure  is_retro  \n",
       "0         1.0            0.0       0.0  \n",
       "1         1.0            0.0       0.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean the data for stopwords for every columns\n",
    "cols = ['brand','description', 'brand_category', 'name','details']\n",
    "for col in cols:\n",
    "    data_label[col] = lemmatize_sentence(data_label[col])\n",
    "data_label.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we use tfidf to vectorize the data \n",
    "#we can change the parameters in this code cell\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b[a-zA-Z]{3,}\\b',stop_words=\"english\",binary = True,min_df = 0.005,max_df = 0.7,max_features =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dimensionality of the data is:(3916, 801)\n"
     ]
    }
   ],
   "source": [
    "#apppend the model_data with feature for each column\n",
    "columns = ['brand', 'description', 'brand_category', 'name','details']\n",
    "model_data=pd.DataFrame()\n",
    "for j in columns:\n",
    "    corpus = []\n",
    "    for i in range(0,len(data_label)):\n",
    "        corpus.append(data_label.loc[i,j])\n",
    "    vect = vectorizer.fit_transform(corpus)\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    c=pd.DataFrame(vect.toarray().transpose(), index=terms)\n",
    "    model_data=pd.concat([model_data,c.T],axis = 1)\n",
    "print(f'The Dimensionality of the data is:{model_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split X and Y for model building phase using 0.2 test_size and random_state = 0 to for repeatability of the code\n",
    "X=model_data\n",
    "y=data_label['is_casual'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6716036772216547"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label['is_casual'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6709183673469388\n",
      "0.6721938775510204\n",
      "0.6709183673469388\n",
      "0.8022959183673469\n",
      "0.6709183673469388\n",
      "0.7321428571428571\n",
      "0.7295918367346939\n",
      "0.735969387755102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "size=[[64,8,2],[128,32,4]]\n",
    "epoch=[5,8,10,20]\n",
    "for i in size:\n",
    "    for k in epoch:\n",
    "        nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=i,max_iter=k).fit(X_train, y_train)\n",
    "        y_pred_RF = nn.predict(X_test)\n",
    "        print(accuracy_score(y_pred_RF,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46833503575076607"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for other categories of style\n",
    "X=model_data\n",
    "y=data_label['is_modern'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data_label['is_modern'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025510204081632\n",
      "0.6326530612244898\n",
      "0.7142857142857143\n",
      "0.7346938775510204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "size=[[64,8,2]]\n",
    "epoch=[5,8,10,20]\n",
    "for i in size:\n",
    "    for k in epoch:\n",
    "        nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=i,max_iter=k).fit(X_train, y_train)\n",
    "        y_pred_RF = nn.predict(X_test)\n",
    "        print(accuracy_score(y_pred_RF,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20531154239019409"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for category with low 1's\n",
    "X=model_data\n",
    "y=data_label['is_edgy'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data_label['is_edgy'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7844387755102041\n",
      "0.7844387755102041\n",
      "0.7844387755102041\n",
      "0.8188775510204082\n",
      "0.7844387755102041\n",
      "0.7844387755102041\n",
      "0.7844387755102041\n",
      "0.8278061224489796\n",
      "0.7844387755102041\n",
      "0.7844387755102041\n",
      "0.7844387755102041\n",
      "0.8086734693877551\n",
      "0.7844387755102041\n",
      "0.7844387755102041\n",
      "0.7844387755102041\n",
      "0.8227040816326531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "size=[[64,8,2],[128,16,4],[256,64,2],[32,4,2]]\n",
    "epoch=[5,8,10,20]\n",
    "for i in size:\n",
    "    for k in epoch:\n",
    "        nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=i,max_iter=k).fit(X_train, y_train)\n",
    "        y_pred_RF = nn.predict(X_test)\n",
    "        print(accuracy_score(y_pred_RF,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network is performing better than normal but it's not very good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46833503575076607"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train-test split for naive bayes. Keeping the random_State = 0 for reporducibility\n",
    "X=model_data\n",
    "y=data_label['is_modern'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining Gaussian classifier\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1834.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label['is_modern'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random is :0.46833503575076607\n",
      "predicted is : 0.6951530612244898\n"
     ]
    }
   ],
   "source": [
    "print(f'random is :{data_label.is_modern.sum()/len(data_label)}')\n",
    "y_pred_NB = classifier.predict(X_test)\n",
    "print(f'predicted is : {accuracy_score(y_pred_NB,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=model_data\n",
    "y=data_label['is_casual'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random is :0.6716036772216547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6823979591836735"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f'random is :{data_label.is_casual.sum()/len(data_label)}')\n",
    "y_pred_NB = classifier.predict(X_test)\n",
    "accuracy_score(y_pred_NB,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20531154239019409"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=model_data\n",
    "y=data_label['is_edgy'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data_label['is_edgy'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49489795918367346"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred_NB = classifier.predict(X_test)\n",
    "accuracy_score(y_pred_NB,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes classifier is also struggling with smaller percentages of 1. But, it's predicting not overfitting like neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20531154239019409"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=model_data\n",
    "y=data_label['is_edgy'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data_label['is_edgy'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  81.63265306122449\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train,y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6716036772216547"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=model_data\n",
    "y=data_label['is_casual'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data_label['is_casual'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  81.88775510204081\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train,y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46833503575076607"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=model_data\n",
    "y=data_label['is_modern'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data_label['is_modern'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  73.08673469387756\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train,y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46833503575076607"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=model_data\n",
    "y=data_label['is_modern'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data_label['is_modern'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6926020408163265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg=LogisticRegression(n_jobs=1, C=1e5)\n",
    "               \n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6716036772216547"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=model_data\n",
    "y=data_label['is_casual'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data_label['is_casual'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7653061224489796\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20531154239019409"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=model_data\n",
    "y=data_label['is_edgy'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "data_label['is_edgy'].sum()/len(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.75\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM is performing the best among these models. Even logistic is doing decently well mostly because of sparse data and less data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
